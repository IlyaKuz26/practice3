{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark_preprocessingV2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL1iM0kt7A0u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from os.path import dirname"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_columns(dirpath):\n",
        "\n",
        "  filename = glob(dirpath+'/*.xlsx')[0]\n",
        "\n",
        "  data = pd.read_excel(\n",
        "        filename,\n",
        "        sheet_name='report',\n",
        "        engine='openpyxl',\n",
        "        header=3,\n",
        "        index_col=0,\n",
        "        nrows=0)\n",
        "  \n",
        "  regex = re.compile(r'(\\d\\d\\d\\d), (.+)')\n",
        "\n",
        "  common_cols = []\n",
        "  mapping = {}\n",
        "\n",
        "  for column_name in data.columns:\n",
        "      feature = regex.match(column_name)\n",
        "\n",
        "      if feature:\n",
        "          year = int(feature.group(1))\n",
        "\n",
        "          if year not in mapping:\n",
        "            mapping[year] = {}\n",
        "          mapping[year][column_name] = feature.group(2)\n",
        "      else:\n",
        "          common_cols.append(column_name)\n",
        "  \n",
        "  return common_cols, mapping\n",
        "\n"
      ],
      "metadata": {
        "id": "XE-Itqmkjo9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_spark(dirpath):\n",
        "\n",
        "  common_cols, mapping = get_columns(dirpath)\n",
        "  \n",
        "  result = None\n",
        "\n",
        "  for filename in tqdm(glob(dirpath+'/*.xlsx'), desc=\"Files\"):\n",
        "\n",
        "    data = pd.read_excel(\n",
        "        filename,\n",
        "        sheet_name='report',\n",
        "        engine='openpyxl',\n",
        "        header=3,\n",
        "        index_col=0)\n",
        "\n",
        "    data.dropna(axis=0, subset=['Наименование'], inplace=True) #Удаление 2 пустых строчек в конце таблицы\n",
        "\n",
        "    for year in mapping:\n",
        "        df = data[common_cols + list(mapping[year].keys())]\n",
        "        df = df.rename(columns=mapping[year])\n",
        "        df.insert(9, 'Год', year, True)\n",
        "\n",
        "        if result is not None:\n",
        "            result = pd.concat([result, df])\n",
        "        else:\n",
        "            result = df\n",
        "\n",
        "  result.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "  return result"
      ],
      "metadata": {
        "id": "OYU1sNIB7ccX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirpath = r'/content/drive/MyDrive/ЭкоТомск/practice3/СПАРК 2020'\n",
        "df = read_spark(dirpath)\n",
        "savepath = dirname(dirpath)\n",
        "df.to_csv(f\"{savepath}/spark.csv\")\n",
        "df.to_pickle(f\"{savepath}/spark.pkl\")\n"
      ],
      "metadata": {
        "id": "VC87gSmFVo-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ddab00d-67fa-466d-80be-be26fe3788a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Files: 100%|██████████| 193/193 [27:58<00:00,  8.70s/it]\n"
          ]
        }
      ]
    }
  ]
}